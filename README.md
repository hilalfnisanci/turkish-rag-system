# ğŸ‡¹ğŸ‡· Turkish RAG System

Production-ready Retrieval-Augmented Generation (RAG) system for Turkish documents.

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![LangChain](https://img.shields.io/badge/LangChain-1.0+-purple.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

## âœ¨ Features

- ğŸ“„ **Turkish Document Support** - PDF and TXT file processing
- ğŸ” **Vector Similarity Search** - ChromaDB integration
- ğŸ¤– **OpenAI LLM Integration** - GPT-3.5-turbo powered responses
- ğŸŒ **REST API** - Clean FastAPI backend
- ğŸ¨ **Modern UI** - Simple and intuitive web interface
- ğŸ³ **Docker Ready** - One-command deployment

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose (recommended)
- Python 3.10+ (for local development)
- OpenAI API key

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/YOUR_USERNAME/turkish-rag-system.git
cd turkish-rag-system
```

2. **Create `.env` file**
```bash
echo "OPENAI_API_KEY=your-api-key-here" > .env
```

3. **Run with Docker**
```bash
docker-compose up
```

4. **Open in browser**
```
http://localhost:8000/static/index.html
```

## ğŸ“– Usage

### Upload Documents
1. Click "Choose Files" and select your Turkish PDF/TXT files
2. Click "YÃ¼kle" (Upload) button
3. Wait for "âœ… uploaded" confirmation

### Ask Questions
1. Type your question in Turkish in the text area
2. Click "Soru Sor" (Ask Question)
3. Get AI-powered answers with source references

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚â”€â”€â”€â”€â”€â–¶â”‚   FastAPI    â”‚â”€â”€â”€â”€â”€â–¶â”‚  ChromaDB   â”‚
â”‚  (HTML/JS)  â”‚      â”‚   Backend    â”‚      â”‚  (Vectors)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   OpenAI     â”‚
                     â”‚  GPT-3.5     â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

- **Backend**: FastAPI (Python)
- **Vector Database**: ChromaDB
- **LLM**: OpenAI GPT-3.5-turbo
- **Embeddings**: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
- **Document Processing**: LangChain Classic + PyPDF
- **Deployment**: Docker + Docker Compose
- **Framework**: LangChain v1.0+

## ğŸ“ API Endpoints

### Health Check
```bash
GET /health
Response: {"status": "ok"}
```

### Upload Documents
```bash
POST /upload
Content-Type: multipart/form-data
Body: files (PDF/TXT)
Response: {"status": "success", "files_processed": 1}
```

### Ask Question
```bash
POST /ask?query=Your+question+here
Response: {
  "question": "...",
  "answer": "...",
  "sources": [...]
}
```

### System Status
```bash
GET /status
Response: {"indexed_documents": 5, "status": "ready"}
```

## ğŸ§ª Development

### Local Setup (without Docker)

**Requirements:**
- Python 3.10 or higher
- OpenAI API key

**Steps:**

1. **Create virtual environment**
```bash
python3.11 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. **Install dependencies**
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

3. **Create `.env` file**
```bash
OPENAI_API_KEY=your-api-key-here
```

4. **Run server**
```bash
python -m uvicorn app.main:app --reload
```

5. **Open browser**
```
http://localhost:8000
```

**Note:** Use `python -m uvicorn` to ensure the correct Python environment is used.

## ğŸ“ Project Structure

```
turkish-rag-system/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â””â”€â”€ document_processor.py # PDF/TXT processing
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html           # Frontend UI
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ temp/                # Uploaded files (auto-cleared)
â”‚   â””â”€â”€ chroma/              # ChromaDB storage
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ¯ Roadmap

- [x] Basic RAG functionality
- [x] Turkish document support  
- [x] Docker deployment
- [x] LangChain v1.0 migration
- [x] Auto-redirect to frontend
- [x] Automatic data cleanup on new uploads
- [ ] Multi-user support
- [ ] Chat history persistence
- [ ] Advanced chunking strategies
- [ ] Fine-tuned Turkish embeddings
- [ ] API authentication
- [ ] Streaming responses

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ‘¤ Author

**Your Name**
- GitHub: [@your-username](https://github.com/your-username)
- LinkedIn: [Your Name](https://linkedin.com/in/your-profile)

## ğŸ™ Acknowledgments

- Built with [LangChain](https://langchain.com/)
- Powered by [OpenAI](https://openai.com/)
- Vector storage by [ChromaDB](https://www.trychroma.com/)

---

â­ Star this repo if you find it useful!
